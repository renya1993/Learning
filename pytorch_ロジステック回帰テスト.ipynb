{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_ロジステック回帰テスト.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWOjsFxCa7y5k16JF77XOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renya1993/Learning/blob/main/pytorch_%E3%83%AD%E3%82%B8%E3%82%B9%E3%83%86%E3%83%83%E3%82%AF%E5%9B%9E%E5%B8%B0%E3%83%86%E3%82%B9%E3%83%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h4PnHzQxgvO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optimizers\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ijb5fVMPyBPI",
        "outputId": "b46b28db-d5fe-488a-9ecf-5b8a76079813"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x1=[]\n",
        "x_t=[]\n",
        "for i in range(100):\n",
        "  if np.random.rand(1)[0]<=0.25:\n",
        "    x1.append([1,0])\n",
        "    x_t.append([1])\n",
        "  elif 0.25 <= np.random.rand(1)[0] <0.5:\n",
        "    x1.append([0,1])\n",
        "    x_t.append([1])   \n",
        "  elif 0.5 <= np.random.rand(1)[0] < 0.75:\n",
        "    x1.append([0,0])\n",
        "    x_t.append([0])   \n",
        "  elif 0.75 <= np.random.rand(1)[0] < 1.0:\n",
        "    x1.append([1,1])\n",
        "    x_t.append([0])  \n",
        "  else:\n",
        "    x1.append([1,0])\n",
        "    x_t.append([1])    \n",
        "\n",
        "x_train=pd.DataFrame(np.array(x1))\n",
        "y_train=pd.DataFrame(np.array(x_t))*100\n",
        "y_train"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0\n",
              "0   100\n",
              "1     0\n",
              "2     0\n",
              "3   100\n",
              "4     0\n",
              "..  ...\n",
              "95  100\n",
              "96  100\n",
              "97    0\n",
              "98    0\n",
              "99  100\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg3rzMfHx3Tj"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super().__init__()\n",
        "    self.l1 =nn.Linear(input_dim,3)\n",
        "    self.a1 =nn.ReLU()\n",
        "    self.l2 =nn.Linear(3,1)\n",
        "    self.a2 =nn.ReLU()\n",
        "    \"\"\"\n",
        "    self.l2 =nn.Linear(128,64)\n",
        "    self.a2 =nn.ReLU()\n",
        "    self.l3 =nn.Linear(64,32)\n",
        "    self.a3 =nn.ReLU()\n",
        "    self.l4 =nn.Linear(32,16)\n",
        "    self.a4 =nn.ReLU()\n",
        "    self.l5 =nn.Linear(2,1)\n",
        "    self.a5 =nn.ReLU()\n",
        "    \"\"\"\n",
        "    self.layers = [self.l1,self.a1,self.l2,self.a2]\n",
        "    \"\"\"\n",
        "    self.layers = [self.l1,self.a1,\n",
        "                   self.l2,self.a2,\n",
        "                   self.l3,self.a3,\n",
        "                   self.l4,self.a4,\n",
        "                   self.l5,self.a5]\n",
        "    \"\"\"\n",
        "  def forward(self,x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "model = MLP(x_train.shape[1],1).to(device)\n"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-MPqBl2x5BP"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP(x_train.shape[1],1).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "def compute_loss(t,y):\n",
        "  return criterion(y,t)\n",
        "\n",
        "optimizer = optimizers.Adam(model.parameters(),lr=1)"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfOqqvC9x8Vu",
        "outputId": "00e6da08-b07e-4705-c480-d298eca74fe1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def train_step(x,t):\n",
        "  model.train()\n",
        "  preds =model(x)\n",
        "  loss = compute_loss(t,preds)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss\n",
        "\n",
        "epochs = 1000\n",
        "train_loss_list=[]\n",
        "test_loss_list=[]\n",
        "\n",
        "\"\"\"\n",
        "データの整形\n",
        "\"\"\"\n",
        "x_train_row = x_train.values.reshape(-1,x_train.shape[1])\n",
        "#x_test_row  = x_test.values.reshape(-1,x_test.shape[1])\n",
        "y_train_row = y_train.values.reshape(-1,1)\n",
        "#y_test_row  = y_test.values.reshape(-1,1)\n",
        "\n",
        "batch_size = 10\n",
        "n_batches = x_train.shape[0] // batch_size\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss = 0\n",
        "  x_train_row,y_train_row = shuffle(x_train_row,y_train_row)\n",
        "  #x_test_row,y_test_row = shuffle(x_test_row,y_test_row)\n",
        "  x_ = torch.Tensor(x_train_row).to(device)\n",
        "  t_ = torch.Tensor(y_train_row).to(device)\n",
        "\n",
        "  for n_batch in range(n_batches):\n",
        "    start = n_batch *batch_size\n",
        "    end = start+batch_size\n",
        "    loss_train = train_step(x_[start:end],t_[start:end]).data.cpu().numpy()\n",
        "    train_loss+=loss_train\n",
        "  #x_t = torch.Tensor(x_test_row).to(device)\n",
        "  #t_t = torch.Tensor(y_test_row).to(device)\n",
        "  #loss_train = train_step(x_,t_).data.cpu().numpy()\n",
        "  #loss_test = compute_loss(x_t,t_t).data.cpu().numpy()\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "  #test_loss_list.append(loss_test)\n",
        "\n",
        "  now_epoch = epoch\n",
        "\n",
        "#plt.plot(np.arange(0,now_epoch+1,1),train_loss_list)\n",
        "#plt.plot(np.arange(0,now_epoch+1,1),test_loss_list)\n",
        "print(now_epoch)\n",
        "print(model(x_))"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999\n",
            "tensor([[100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [100.],\n",
            "        [  0.],\n",
            "        [100.]], grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "yBF3HHuh11uI",
        "outputId": "21df3340-7a73-4bd1-a3a8-d57e56600462"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  1\n",
              "2  1\n",
              "3  1\n",
              "4  1\n",
              "5  1\n",
              "6  1\n",
              "7  1\n",
              "8  1\n",
              "9  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVN-SjhUzU8d",
        "outputId": "a5895bcc-66d3-4cff-878a-e592dbe1ba33"
      },
      "source": [
        "def test_step(x,t):\n",
        "  x = torch.Tensor(x).to(device)\n",
        "  t = torch.Tensor(t).to(device)\n",
        "  model.eval()\n",
        "  preds = model(x)\n",
        "  loss = compute_loss(t,preds)\n",
        "  return loss,preds\n",
        "\n",
        "loss,preds = test_step(x_train_row,y_train_row)\n",
        "test_loss = loss.item()\n",
        "preds = preds.data.cpu().numpy()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "mse_test = MSE(y_train_row,preds)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "\n",
        "print(rmse_test)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWCmBW5Hzs7_",
        "outputId": "1051282b-3b5f-4e88-ebad-0d7038b8e754"
      },
      "source": [
        "'''\n",
        "4.1.3 PyTorch（トイ・プロブレム）\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optimizers\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    '''\n",
        "    多層パーセプトロン\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.a1 = nn.Sigmoid()\n",
        "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.a2 = nn.Sigmoid()\n",
        "\n",
        "        self.layers = [self.l1, self.a1, self.l2, self.a2]\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    np.random.seed(123)\n",
        "    torch.manual_seed(123)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    '''\n",
        "    1. データの準備\n",
        "    '''\n",
        "    N = 300\n",
        "    x, t = datasets.make_moons(N, noise=0.3)\n",
        "    t = t.reshape(N, 1)\n",
        "\n",
        "    x_train_row = x_train_.values.reshape(-1,x_train_.shape[1])\n",
        "    y_train_row = y_train_.values.reshape(-1,1)  \n",
        "\n",
        "    x_train, x_test, t_train, t_test = \\\n",
        "        train_test_split(x_train_row, y_train_row, test_size=0.2)\n",
        "\n",
        "    '''\n",
        "    2. モデルの構築\n",
        "    '''\n",
        "    model = MLP(2, 3, 1).to(device)\n",
        "\n",
        "    '''\n",
        "    3. モデルの学習\n",
        "    '''\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optimizers.SGD(model.parameters(), lr=1)\n",
        "\n",
        "    def compute_loss(t, y):\n",
        "        return criterion(y, t)\n",
        "\n",
        "    def train_step(x, t):\n",
        "        model.train()\n",
        "        preds = model(x)\n",
        "        loss = compute_loss(t, preds)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    epochs = 100\n",
        "    batch_size = 10\n",
        "    n_batches = x_train.shape[0] // batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0.\n",
        "        x_, t_ = shuffle(x_train, t_train)\n",
        "        x_ = torch.Tensor(x_).to(device)\n",
        "        t_ = torch.Tensor(t_).to(device)\n",
        "\n",
        "        for n_batch in range(n_batches):\n",
        "            start = n_batch * batch_size\n",
        "            end = start + batch_size\n",
        "            loss = train_step(x_[start:end], t_[start:end])\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        print('epoch: {}, loss: {:.3}'.format(\n",
        "            epoch+1,\n",
        "            train_loss\n",
        "        ))\n",
        "\n",
        "    '''\n",
        "    4. モデルの評価\n",
        "    '''\n",
        "    def test_step(x, t):\n",
        "        x = torch.Tensor(x).to(device)\n",
        "        t = torch.Tensor(t).to(device)\n",
        "        model.eval()\n",
        "        preds = model(x)\n",
        "        loss = compute_loss(t, preds)\n",
        "\n",
        "        return loss, preds\n",
        "\n",
        "    loss, preds = test_step(x_test, t_test)\n",
        "    test_loss = loss.item()\n",
        "    preds = preds.data.cpu().numpy() > 0.5\n",
        "    test_acc = accuracy_score(t_test, preds)\n",
        "\n",
        "    print('test_loss: {:.3f}, test_acc: {:.3f}'.format(\n",
        "        test_loss,\n",
        "        test_acc\n",
        "    ))"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, loss: 5.17\n",
            "epoch: 2, loss: 4.89\n",
            "epoch: 3, loss: 4.96\n",
            "epoch: 4, loss: 4.83\n",
            "epoch: 5, loss: 4.82\n",
            "epoch: 6, loss: 4.81\n",
            "epoch: 7, loss: 4.83\n",
            "epoch: 8, loss: 4.93\n",
            "epoch: 9, loss: 4.78\n",
            "epoch: 10, loss: 4.76\n",
            "epoch: 11, loss: 4.69\n",
            "epoch: 12, loss: 4.69\n",
            "epoch: 13, loss: 4.56\n",
            "epoch: 14, loss: 4.63\n",
            "epoch: 15, loss: 4.5\n",
            "epoch: 16, loss: 4.4\n",
            "epoch: 17, loss: 4.43\n",
            "epoch: 18, loss: 4.35\n",
            "epoch: 19, loss: 4.24\n",
            "epoch: 20, loss: 4.18\n",
            "epoch: 21, loss: 4.03\n",
            "epoch: 22, loss: 3.91\n",
            "epoch: 23, loss: 3.79\n",
            "epoch: 24, loss: 3.83\n",
            "epoch: 25, loss: 3.62\n",
            "epoch: 26, loss: 3.53\n",
            "epoch: 27, loss: 3.43\n",
            "epoch: 28, loss: 3.32\n",
            "epoch: 29, loss: 3.29\n",
            "epoch: 30, loss: 3.18\n",
            "epoch: 31, loss: 3.12\n",
            "epoch: 32, loss: 3.12\n",
            "epoch: 33, loss: 3.0\n",
            "epoch: 34, loss: 2.92\n",
            "epoch: 35, loss: 2.84\n",
            "epoch: 36, loss: 2.88\n",
            "epoch: 37, loss: 2.78\n",
            "epoch: 38, loss: 2.79\n",
            "epoch: 39, loss: 2.69\n",
            "epoch: 40, loss: 2.71\n",
            "epoch: 41, loss: 2.62\n",
            "epoch: 42, loss: 2.62\n",
            "epoch: 43, loss: 2.57\n",
            "epoch: 44, loss: 2.53\n",
            "epoch: 45, loss: 2.49\n",
            "epoch: 46, loss: 2.47\n",
            "epoch: 47, loss: 2.43\n",
            "epoch: 48, loss: 2.4\n",
            "epoch: 49, loss: 2.41\n",
            "epoch: 50, loss: 2.35\n",
            "epoch: 51, loss: 2.29\n",
            "epoch: 52, loss: 2.29\n",
            "epoch: 53, loss: 2.26\n",
            "epoch: 54, loss: 2.21\n",
            "epoch: 55, loss: 2.19\n",
            "epoch: 56, loss: 2.15\n",
            "epoch: 57, loss: 2.13\n",
            "epoch: 58, loss: 2.08\n",
            "epoch: 59, loss: 2.06\n",
            "epoch: 60, loss: 2.0\n",
            "epoch: 61, loss: 1.99\n",
            "epoch: 62, loss: 1.96\n",
            "epoch: 63, loss: 1.94\n",
            "epoch: 64, loss: 1.86\n",
            "epoch: 65, loss: 1.8\n",
            "epoch: 66, loss: 1.73\n",
            "epoch: 67, loss: 1.65\n",
            "epoch: 68, loss: 1.62\n",
            "epoch: 69, loss: 1.53\n",
            "epoch: 70, loss: 1.41\n",
            "epoch: 71, loss: 1.3\n",
            "epoch: 72, loss: 1.24\n",
            "epoch: 73, loss: 1.13\n",
            "epoch: 74, loss: 1.06\n",
            "epoch: 75, loss: 0.974\n",
            "epoch: 76, loss: 0.909\n",
            "epoch: 77, loss: 0.862\n",
            "epoch: 78, loss: 0.81\n",
            "epoch: 79, loss: 0.751\n",
            "epoch: 80, loss: 0.702\n",
            "epoch: 81, loss: 0.661\n",
            "epoch: 82, loss: 0.627\n",
            "epoch: 83, loss: 0.591\n",
            "epoch: 84, loss: 0.561\n",
            "epoch: 85, loss: 0.54\n",
            "epoch: 86, loss: 0.512\n",
            "epoch: 87, loss: 0.481\n",
            "epoch: 88, loss: 0.462\n",
            "epoch: 89, loss: 0.443\n",
            "epoch: 90, loss: 0.421\n",
            "epoch: 91, loss: 0.406\n",
            "epoch: 92, loss: 0.388\n",
            "epoch: 93, loss: 0.373\n",
            "epoch: 94, loss: 0.359\n",
            "epoch: 95, loss: 0.345\n",
            "epoch: 96, loss: 0.334\n",
            "epoch: 97, loss: 0.323\n",
            "epoch: 98, loss: 0.311\n",
            "epoch: 99, loss: 0.301\n",
            "epoch: 100, loss: 0.291\n",
            "test_loss: 0.031, test_acc: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKuYj7Vf_ZbK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}